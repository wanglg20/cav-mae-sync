<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment">
  <meta name="keywords" content="Audio-Visual, Self-Supervised Learning, Deep Learning">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/neural_network_icon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <!-- Home button removed -->
    </div>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://www.linkedin.com/in/edsonroteia/">Edson Araujo</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://people.csail.mit.edu/roudi/">Andrew Rouditchenko</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://yuangongnd.github.io/">Yuan Gong</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.csail.mit.edu/person/saurabhchand-bhati">Saurabhchand Bhati</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://research.ibm.com/people/samuel-thomas">Samuel Thomas</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=WbO7tjYAAAAJ&hl=en">Leonid Karlinsky</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="https://research.ibm.com/people/rogerio-feris">Rogerio Feris</a><sup>3,4</sup>,</span>
            <span class="author-block">
              <a href="https://www.csail.mit.edu/person/jim-glass">James R. Glass</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://hildekuehne.github.io/">Hilde Kuehne</a><sup>1,4,5</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Goethe University Frankfurt,</span>
            <span class="author-block"><sup>2</sup>MIT,</span>
            <span class="author-block"><sup>3</sup>IBM Research,</span>
            <span class="author-block"><sup>4</sup>MIT-IBM Watson AI Lab,</span>
            <span class="author-block"><sup>5</sup>Tuebingen AI Center/University of Tuebingen</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Update links -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.01237" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- New Code Button -->
              <span class="link-block">
                <a href="https://github.com/edsonroteia/cav-mae-sync" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  <span class="tooltip">Coming soon! :)</span>
                </a>
              </span>
              <!-- Keep similar structure for arXiv, code, etc. -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered is-vcentered">
      <!-- Teaser Figure -->
      <div class="column is-5 has-text-centered">
        <div class="content">
          <figure class="image">
            <img src="./static/images/teaser_v8.png" alt="Teaser figure" style="width: 100%; height: auto;"/>
            <p class="has-text-centered is-size-6 mt-2">
              By representing audio with multiple finer-grained representations aligned with individual video frames, CAV-MAE Sync improves the precision of audio-visual alignment.
            </p>
          </figure>
        </div>
      </div>

      <!-- Abstract -->
      <div class="column is-7">
        <h2 class="title is-3 has-text-centered">Abstract</h2>
        <div class="content">
          <p>
            Recent advances in audio-visual learning have shown promising results in learning representations across modalities. However, most approaches rely on global audio representations that fail to capture fine-grained temporal correspondences with visual frames. Additionally, existing methods often struggle with conflicting optimization objectives when trying to jointly learn reconstruction and cross-modal alignment.
          </p>
          <p>
            In this work, we propose CAV-MAE Sync as a simple yet effective extension of the original CAV-MAE framework for self-supervised audio-visual learning. We address three key challenges:
          </p>
          <ul class="has-text-left ml-6">
            <li>First, we tackle the granularity mismatch between modalities by treating audio as a temporal sequence aligned with video frames, rather than using global representations.</li>
            <li>Second, we resolve conflicting optimization goals by separating contrastive and reconstruction objectives through dedicated global tokens.</li>
            <li>Third, we improve spatial localization by introducing learnable register tokens that reduce the semantic load on patch tokens.</li>
          </ul>
          <p>
            We evaluate the proposed approach on AudioSet, VGG Sound, and the ADE20K Sound dataset on zero-shot retrieval, classification, and localization tasks demonstrating state-of-the-art performance and outperforming more complex architectures.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-10">
          <h2 class="title is-3">Method Overview</h2>
          <div class="content">
            <img src="./static/images/method_v6.3.png" alt="Method overview"/>
            <p class="has-text-centered">
              Our model processes video frames and audio segments in parallel through separate encoders $E_a$ and $E_v$, with the audio encoder $E_a$ operating on finer temporal granularity to better align with visual frames. Both modalities interact through the Joint Layer $L$ and the Joint Decoder $D$.
            </p>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Results</h2>
    
    <!-- Quantitative Results -->
    <section class="section">
      <div class="container is-max-desktop">
        <h3 class="title is-4">Quantitative Results</h3>
        <!-- <div class="content">
          <img src="./static/images/results.png" alt="Quantitative results"/>
          <p class="has-text-centered">
            Performance comparison on standard audio-visual benchmarks
          </p>
        </div> -->
        <table class="table is-striped is-bordered is-hoverable" style="border-collapse: collapse; width: 100%;">
          <thead>
            <tr>
              <th rowspan="2" style="text-align: center; vertical-align: middle;">Visual to Audio</th>
              <th colspan="3" style="text-align: center;">AudioSet Eval Subset</th>
              <th colspan="3" style="text-align: center;">VGGSound Eval Subset</th>
              <th rowspan="2" style="text-align: center; vertical-align: middle;">Audio to Visual</th>
              <th colspan="3" style="text-align: center;">AudioSet Eval Subset</th>
              <th colspan="3" style="text-align: center;">VGGSound Eval Subset</th>
            </tr>
            <tr>
              <th>R@1</th>
              <th>R@5</th>
              <th>R@10</th>
              <th>R@1</th>
              <th>R@5</th>
              <th>R@10</th>
              <th>R@1</th>
              <th>R@5</th>
              <th>R@10</th>
              <th>R@1</th>
              <th>R@5</th>
              <th>R@10</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="color: lightgray;">VAB-Encodec</td>
              <td style="color: lightgray;">39.5</td>
              <td style="color: lightgray;">65.4</td>
              <td style="color: lightgray;">74.6</td>
              <td style="color: lightgray;">33.5</td>
              <td style="color: lightgray;">63.3</td>
              <td style="color: lightgray;">74.3</td>
              <td></td>
              <td style="color: lightgray;">37.5</td>
              <td style="color: lightgray;">64.0</td>
              <td style="color: lightgray;">73.7</td>
              <td style="color: lightgray;">34.9</td>
              <td style="color: lightgray;">62.7</td>
              <td style="color: lightgray;">73.1</td>
            </tr>
            <tr>
              <td>CAV-MAE</td>
              <td>16.1</td>
              <td>38.6</td>
              <td>49.3</td>
              <td>14.7</td>
              <td>35.3</td>
              <td>45.9</td>
              <td></td>
              <td>9.5</td>
              <td>22.6</td>
              <td>32.4</td>
              <td>8.3</td>
              <td>23.8</td>
              <td>32.4</td>
            </tr>
            <tr>
              <td>CAV-MAE<sup>Scale+</sup></td>
              <td>18.8</td>
              <td>39.5</td>
              <td>50.1</td>
              <td>14.8</td>
              <td>34.2</td>
              <td>44.0</td>
              <td></td>
              <td>15.1</td>
              <td>34.0</td>
              <td>43.0</td>
              <td>12.8</td>
              <td>30.4</td>
              <td>40.3</td>
            </tr>
            <tr>
              <td>LanguageBind</td>
              <td>6.4</td>
              <td>20.2</td>
              <td>28.3</td>
              <td>10.3</td>
              <td>30.1</td>
              <td>39.7</td>
              <td></td>
              <td>4.4</td>
              <td>15.0</td>
              <td>22.5</td>
              <td>6.5</td>
              <td>22.7</td>
              <td>33.5</td>
            </tr>
            <tr>
              <td>AVSiam</td>
              <td>19.7</td>
              <td>-</td>
              <td>-</td>
              <td>19.0</td>
              <td>-</td>
              <td>-</td>
              <td></td>
              <td>17.6</td>
              <td>-</td>
              <td>-</td>
              <td>20.4</td>
              <td>-</td>
              <td>-</td>
            </tr>
            <tr>
              <td>ImageBind</td>
              <td>22.1</td>
              <td>43.2</td>
              <td>52.6</td>
              <td>21.6</td>
              <td>43.4</td>
              <td>52.9</td>
              <td></td>
              <td>20.8</td>
              <td>42.6</td>
              <td>51.6</td>
              <td>20.7</td>
              <td>43.2</td>
              <td>53.4</td>
            </tr>
            <tr>
              <td><strong>Ours</strong></td>
              <td><strong>35.2</strong></td>
              <td><strong>58.3</strong></td>
              <td><strong>67.6</strong></td>
              <td><strong>27.9</strong></td>
              <td><strong>51.7</strong></td>
              <td><strong>61.8</strong></td>
              <td></td>
              <td><strong>27.9</strong></td>
              <td><strong>52.4</strong></td>
              <td><strong>62.2</strong></td>
              <td><strong>23.2</strong></td>
              <td><strong>46.2</strong></td>
              <td><strong>58.1</strong></td>
            </tr>
          </tbody>
        </table>
        <p class="has-text-centered">
          Zero-shot retrieval results on AudioSet and VGGSound for Visual to Audio (Vâ†’A) and Audio to Visual (Aâ†’V) tasks. Our model achieves state-of-the-art zero-shot performance across all retrieval metrics (R@1, R@5, R@10) on both datasets, surpassing baselines like ImageBind and AVSiam. Fine-tuned VAB-Encodec scores are provided as an upper bound for comparison.
        </p>
      </div>
    </section>
</section>

<section class="section has-text-centered">
  <div class="container is-max-desktop">
    <p class="is-size-4">ðŸš§</p>
    <p class="is-size-5">Webpage under construction. Keep an eye out for updates on <a href="https://github.com/edsonroteia/cav-mae-sync">GitHub</a>!</p>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{araujo2025cavmae,
  title={CAV-MAE Sync: Improving Contrastive Audio-Visual Mask Autoencoders via Fine-Grained Alignment},
  author={Edson Araujo and Andrew Rouditchenko and Yuan Gong and Saurabhchand Bhati and Samuel Thomas and Brian Kingsbury and Leonid Karlinsky and Rogerio Feris and James R. Glass and Hilde Kuehne},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2025}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="#">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website template from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<style>
.link-block {
  position: relative; /* Position relative for tooltip positioning */
}

.tooltip {
  visibility: hidden; /* Hidden by default */
  width: 150px; /* Increased width for better fitting */
  background-color: rgba(0, 0, 0, 0.8); /* Slightly transparent background */
  color: #fff; /* Text color */
  text-align: center; /* Centered text */
  border-radius: 8px; /* Rounded corners */
  padding: 12px; /* Increased padding for more space */
  position: absolute; /* Positioning */
  z-index: 1; /* On top of other elements */
  bottom: -50px; /* Position below the button */
  left: 50%; /* Center it */
  margin-left: -75px; /* Adjust for centering */
  opacity: 0; /* Hidden by default */
  transition: opacity 0.3s; /* Fade effect */
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2); /* Subtle shadow for depth */
  font-size: 14px; /* Adjusted font size */
}

.link-block a:hover .tooltip {
  visibility: visible; /* Show tooltip on hover */
  opacity: 1; /* Fade in */
}
</style>

</body>
</html>
